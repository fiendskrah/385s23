[
  {
    "objectID": "slides/week-04/06-centrography.html",
    "href": "slides/week-04/06-centrography.html",
    "title": "Centrography for Point Patterns",
    "section": "",
    "text": "Centrography refers to a set of descriptive statistics that provide summary descriptions of point patterns.\nThis notebook introduces three types of centrography analysis for point patterns in pysal.\n\nCentral Tendency\nDispersion and Orientation\nShape Analysis\n\nWe also illustrate centrography analysis using two simulated datasets. See Another Example\n\nCentral Tendency\n\nmean_center: calculate the mean center of the unmarked point pattern.\nweighted_mean_center: calculate the weighted mean center of the marked point pattern.\nmanhattan_median: calculate the manhattan median\neuclidean_median: calculate the Euclidean median\n\nDispersion and Orientation\n\nstd_distance: calculate the standard distance\nstandard deviational ellipse\n\nShape Analysis\n\nhull: calculate the convex hull of the point pattern\nmbr: calculate the minimum bounding box (rectangle)\n\n\nAll of the above functions operate on a series of coordinate pairs. That is, the data type of the first argument should be \\((n,2)\\) array_like. In case that you have a point pattern (PointPattern instance), you need to pass its attribute “points” instead of itself to these functions.\n\nimport numpy as np\nfrom pointpats import PointPattern\n%matplotlib inline\nimport matplotlib.pyplot as plt\npoints = [[66.22, 32.54], [22.52, 22.39], [31.01, 81.21],\n          [9.47, 31.02],  [30.78, 60.10], [75.21, 58.93],\n          [79.26,  7.68], [8.23, 39.93],  [98.73, 77.17],\n          [89.78, 42.53], [65.19, 92.08], [54.46, 8.48]]\npp = PointPattern(points) #create a point pattern \"pp\" from list\npp.points \n\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1492: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1208: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n\n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      66.22\n      32.54\n    \n    \n      1\n      22.52\n      22.39\n    \n    \n      2\n      31.01\n      81.21\n    \n    \n      3\n      9.47\n      31.02\n    \n    \n      4\n      30.78\n      60.10\n    \n    \n      5\n      75.21\n      58.93\n    \n    \n      6\n      79.26\n      7.68\n    \n    \n      7\n      8.23\n      39.93\n    \n    \n      8\n      98.73\n      77.17\n    \n    \n      9\n      89.78\n      42.53\n    \n    \n      10\n      65.19\n      92.08\n    \n    \n      11\n      54.46\n      8.48\n    \n  \n\n\n\n\n\ntype(pp.points)\n\npandas.core.frame.DataFrame\n\n\nWe can use PointPattern class method plot to visualize pp.\n\npp.plot()\n\n\n\n\n\nfrom pointpats.centrography import (hull, mbr, mean_center,\n                                    weighted_mean_center, manhattan_median,\n                                    std_distance,euclidean_median,ellipse)"
  },
  {
    "objectID": "slides/week-04/06-centrography.html#mean-center-x_mcy_mc",
    "href": "slides/week-04/06-centrography.html#mean-center-x_mcy_mc",
    "title": "Centrography for Point Patterns",
    "section": "Mean Center \\((x_{mc},y_{mc})\\)",
    "text": "Mean Center \\((x_{mc},y_{mc})\\)\n\\[x_{mc}=\\frac{1}{n} \\sum^n_{i=1}x_i\\] \\[y_{mc}=\\frac{1}{n} \\sum^n_{i=1}y_i\\]\n\nmc = mean_center(pp.points)\nmc\n\narray([52.57166667, 46.17166667])\n\n\n\npp.plot()\nplt.plot(mc[0], mc[1], 'b^', label='Mean Center')\nplt.legend(numpoints=1)\n\n<matplotlib.legend.Legend at 0x7f987ff3d660>"
  },
  {
    "objectID": "slides/week-04/06-centrography.html#weighted-mean-center-x_wmcy_wmc",
    "href": "slides/week-04/06-centrography.html#weighted-mean-center-x_wmcy_wmc",
    "title": "Centrography for Point Patterns",
    "section": "Weighted Mean Center \\((x_{wmc},y_{wmc})\\)",
    "text": "Weighted Mean Center \\((x_{wmc},y_{wmc})\\)\n\\[x_{wmc}=\\sum^n_{i=1} \\frac{w_i x_i}{\\sum^n_{i=1}w_i}\\] \\[y_{wmc}=\\sum^n_{i=1} \\frac{w_i y_i}{\\sum^n_{i=1}w_i}\\]\nThe Weighted mean center is meant for marked point patterns. Aside from the first argument which is a series of \\((x,y)\\) coordinates in weighted_mean_center function, we need to specify its second argument which is the weight for each event point.\n\nweights = np.arange(12)\nweights\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n\n\n\nwmc = weighted_mean_center(pp.points, weights)\nwmc\n\narray([60.51681818, 47.76848485])\n\n\n\npp.plot() #use class method \"plot\" to visualize point pattern\nplt.plot(mc[0], mc[1], 'b^', label='Mean Center') \nplt.plot(wmc[0], wmc[1], 'gd', label='Weighted Mean Center')\nplt.legend(numpoints=1)\n\n<matplotlib.legend.Legend at 0x7f987ff9b310>"
  },
  {
    "objectID": "slides/week-04/06-centrography.html#manhattan-median-x_mmy_mm",
    "href": "slides/week-04/06-centrography.html#manhattan-median-x_mmy_mm",
    "title": "Centrography for Point Patterns",
    "section": "Manhattan Median \\((x_{mm},y_{mm})\\)",
    "text": "Manhattan Median \\((x_{mm},y_{mm})\\)\n\\[min  f(x_{mm},y_{mm})= \\sum^n_{i=1}(|x_i-x_{mm}|+|y_i-y_{mm}|)\\]\nThe Manhattan median is the location which minimizes the absolute distance to all the event points. It is an extension of the median measure in one-dimensional space to two-dimensional space. Since in one-dimensional space, a median is the number separating the higher half of a dataset from the lower half, we define the Manhattan median as a tuple whose first element is the median of \\(x\\) coordinates and second element is the median of \\(y\\) coordinates.\nThough Manhattan median can be found very quickly, it is not unique if you have even number of points. In this case, pysal handles the Manhattan median the same way as numpy.median: return the average of the two middle values.\n\n#get the number of points in point pattern \"pp\"\npp.n\n\n12\n\n\n\n#Manhattan Median is not unique for \"pp\"\nmm = manhattan_median(pp.points)\nmm\n\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/pointpats/centrography.py:208: UserWarning: Manhattan Median is not unique for even point patterns.\n  warnings.warn(s)\n\n\narray([59.825, 41.23 ])\n\n\n\npp.plot()\nplt.plot(mc[0], mc[1], 'b^', label='Mean Center')\nplt.plot(wmc[0], wmc[1], 'gd', label='Weighted Mean Center')\nplt.plot(mm[0], mm[1], 'rv', label='Manhattan Median')\nplt.legend(numpoints=1)\n\n<matplotlib.legend.Legend at 0x7f987fe38a90>"
  },
  {
    "objectID": "slides/week-04/06-centrography.html#euclidean-median-x_emy_em",
    "href": "slides/week-04/06-centrography.html#euclidean-median-x_emy_em",
    "title": "Centrography for Point Patterns",
    "section": "Euclidean Median \\((x_{em},y_{em})\\)",
    "text": "Euclidean Median \\((x_{em},y_{em})\\)\n\\[min  f(x_{em},y_{em})= \\sum^n_{i=1} \\sqrt{(x_i-x_{em})^2+(y_i-y_{em})^2}\\]\nThe Euclidean Median is the location from which the sum of the Euclidean distances to all points in a distribution is a minimum. It is an optimization problem and very important for more general location allocation problems. There is no closed form solution. We can use first iterative algorithm (Kuhn and Kuenne, 1962) to approximate Euclidean Median.\nBelow, we define a function named median_center with the first argument points a series of \\((x,y)\\) coordinates and the second argument crit the convergence criterion.\n\ndef median_center(points, crit=0.0001):\n    points = np.asarray(points)\n    x0, y0 = points.mean(axis=0)\n    dx = np.inf\n    dy = np.inf\n    iteration = 0\n    while np.abs(dx) > crit or np.abs(dy) > crit:\n        xd = points[:, 0] - x0\n        yd = points[:, 1] - y0\n        d = np.sqrt(xd*xd + yd*yd)\n        w = 1./d\n        w = w / w.sum()\n        x1 = w * points[:, 0]\n        x1 = x1.sum()\n        y1 = w * points[:, 1]\n        y1 = y1.sum()\n        dx = x1 - x0\n        dy = y1 - y0\n        iteration +=1 \n        print(x0, x1, dx, dy, d.sum(), iteration)\n        x0 = x1\n        y0 = y1\n               \n    return x1, y1\n\n\nmedian_center(pp.points, crit=.0001)\n\n52.57166666666668 53.178128280602785 0.606461613936105 -0.9290354286335258 466.24479074356606 1\n53.178128280602785 53.56643624463614 0.388307964033352 -0.4199402653980684 465.9311160558993 2\n53.56643624463614 53.80720376806838 0.24076752343224683 -0.1974862190386233 465.84555867343346 3\n53.80720376806838 53.95348076207835 0.1462769940099662 -0.09642613786996179 465.8197750145871 4\n53.95348076207835 54.04117257066307 0.08769180858472225 -0.04872250646902643 465.8115372002813 5\n54.04117257066307 54.09327726928146 0.05210469861838618 -0.025370793047137852 465.80882301324334 6\n54.09327726928146 54.12405125525861 0.030773985977148755 -0.013552246205456697 465.8079149010591 7\n54.12405125525861 54.14215248769505 0.018101232436443127 -0.00739190209046825 465.8076087750224 8\n54.14215248769505 54.15276956049696 0.010617072801906602 -0.0040992658298719675 465.8075052025632 9\n54.15276956049696 54.15898467957115 0.0062151190741914775 -0.0023026998071102867 465.80747009858044 10\n54.15898467957115 54.16261796248172 0.0036332829105703013 -0.0013061853179365812 465.80745819050844 11\n54.16261796248172 54.16473989468326 0.002121932201539778 -0.0007463404183738476 465.80745414933307 12\n54.16473989468326 54.165978319450346 0.00123842476708802 -0.00042875101595285514 465.80745277762423 13\n54.165978319450346 54.166700756153695 0.0007224367033487056 -0.00024727631074483725 465.80745231197506 14\n54.166700756153695 54.16712204754273 0.0004212913890384584 -0.00014302182778891392 465.8074521538953 15\n54.16712204754273 54.16736766581608 0.00024561827334679265 -8.289363293556562e-05 465.8074521002288 16\n54.16736766581608 54.167510839857464 0.0001431740413835314 -4.8115880247223686e-05 465.80745208200943 17\n54.167510839857464 54.167594287646125 8.344778866131719e-05 -2.7959041396741213e-05 465.807452075824 18\n\n\n(54.167594287646125, 44.42430865883205)\n\n\nAfter 18 iterations, the convergence criterion is reached. The Euclidean Median is \\((54.167594287646125,44.424308658832047)\\).\nWe can also call the function euclidean_median in pysal to calculate the Euclidean Median.\n\nem = euclidean_median(pp.points)\nem\n\narray([54.16770671, 44.4242589 ])\n\n\nThe two results we get from euclidean_median function in pysal and the median_center function we define here are very much the same.\n\npp.plot()\nplt.plot(mc[0], mc[1], 'b^', label='Mean Center')\nplt.plot(wmc[0], wmc[1], 'gd', label='Weighted Mean Center')\nplt.plot(mm[0], mm[1], 'rv', label='Manhattan Median')\nplt.plot(em[0], em[1], 'm+', label='Euclidean Median')\nplt.legend(numpoints=1)\n\n<matplotlib.legend.Legend at 0x7f987fe1e0b0>"
  },
  {
    "objectID": "slides/week-04/06-centrography.html#standard-distance-standard-distance-circle",
    "href": "slides/week-04/06-centrography.html#standard-distance-standard-distance-circle",
    "title": "Centrography for Point Patterns",
    "section": "Standard Distance & Standard Distance Circle",
    "text": "Standard Distance & Standard Distance Circle\n\\[SD = \\displaystyle \\sqrt{\\frac{\\sum^n_{i=1}(x_i-x_{m})^2}{n} + \\frac{\\sum^n_{i=1}(y_i-y_{m})^2}{n}}\\]\nThe Standard distance is closely related to the usual definition of the standard deviation of a data set, and it provides a measure of how dispersed the events are around their mean center \\((x_m,y_m)\\). Taken together, these measurements can be used to plot a summary circle (standard distance circle) for the point pattern, centered at \\((x_m,y_m)\\) with radius \\(SD\\), as shown below.\n\nstdd = std_distance(pp.points)\nstdd\n\n40.14980648908671\n\n\nPlot mean center as well as the standard distance circle.\n\ncircle1=plt.Circle((mc[0], mc[1]),stdd,color='r')\nax = pp.plot(get_ax=True, title='Standard Distance Circle')\nax.add_artist(circle1)\nplt.plot(mc[0], mc[1], 'b^', label='Mean Center')\nax.set_aspect('equal')\nplt.legend(numpoints=1)\n\n<matplotlib.legend.Legend at 0x7f987fdf5de0>\n\n\n\n\n\nFrom the above figure, we can observe that there are five points outside the standard distance circle which are potential outliers."
  },
  {
    "objectID": "slides/week-04/06-centrography.html#standard-deviational-ellipse",
    "href": "slides/week-04/06-centrography.html#standard-deviational-ellipse",
    "title": "Centrography for Point Patterns",
    "section": "Standard Deviational Ellipse",
    "text": "Standard Deviational Ellipse\nCompared with standard distance circle which measures dispersion using a single parameter \\(SD\\), standard deviational ellipse measures dispersion and trend in two dimensions through angle of rotation \\(\\theta\\), dispersion along major axis \\(s_x\\) and dispersion along minor axis \\(s_y\\):\n\nMajor axis defines the direction of maximum spread in the distribution. \\(s_x\\) is the semi-major axis (half the length of the major axis):\n\n\\[ s_x = \\displaystyle \\sqrt{\\frac{2(\\sum_{i=1}^n (x_i-\\bar{x})\\cos(\\theta) - \\sum_{i=1}^n (y_i-\\bar{y})\\sin(\\theta))^2}{n-2}}\\]\n\nMinor axis defines the direction of minimum spread and is orthogonal to major axis. \\(s_y\\) is the semi-minor axis (half the length of the minor axis):\n\n\\[ s_y = \\displaystyle \\sqrt{\\frac{2(\\sum_{i=1}^n (x_i-\\bar{x})\\sin(\\theta) - \\sum_{i=1}^n (y_i-\\bar{y})\\cos(\\theta))^2}{n-2}}\\]\n\nThe ellipse is rotated clockwise through an angle \\(\\theta\\):\n\n\\[\\theta = \\displaystyle \\arctan{\\{ (\\sum_i(x_i-\\bar{x})^2-\\sum_i(y_i-\\bar{y})^2) + \\frac{[(\\sum_i(x_i-\\bar{x})^2-\\sum_i(y_i-\\bar{y})^2)^2 + 4(\\sum_i(x-\\bar{x})(y_i-\\bar{y}))^2]^\\frac{1}{2}}{2\\sum_i(x-\\bar{x})(y_i-\\bar{y})}\\}}\\]\n\nsx, sy, theta = ellipse(pp.points)\nsx, sy, theta\n\n(39.62386788646298, 42.753818949026815, 1.1039268428650906)\n\n\n\ntheta_degree = np.degrees(theta) #need degree of rotation to plot the ellipse\ntheta_degree\n\n63.250348987371304\n\n\nThe Standard Deviational Ellipse for the point pattern is rotated clockwise by \\(63.25^{\\circ}\\).\n\nfrom matplotlib.patches import Ellipse\nfrom pylab import figure, show,rand\nfig = figure()\n#ax = fig.add_subplot(111, aspect='equal')\ne = Ellipse(xy=mean_center(pp.points), width=sx*2, height=sy*2, angle=-theta_degree) #angle is rotation in degrees (anti-clockwise)\nax = pp.plot(get_ax=True, title='Standard Deviational Ellipse')\nax.add_artist(e)\ne.set_clip_box(ax.bbox)\ne.set_facecolor([0.8,0,0])\ne.set_edgecolor([1,0,0])\nax.set_xlim(0,100)\nax.set_ylim(0,100)\nax.set_aspect('equal')\nplt.plot(mc[0], mc[1], 'b^', label='Mean Center')\nplt.legend(numpoints=1)\nshow()\n\n<Figure size 672x480 with 0 Axes>"
  },
  {
    "objectID": "slides/week-04/06-centrography.html#convex-hull",
    "href": "slides/week-04/06-centrography.html#convex-hull",
    "title": "Centrography for Point Patterns",
    "section": "Convex Hull",
    "text": "Convex Hull\nThe convex hull of a point pattern pp is the smallest convex set that contains pp. We can call function hull to caculate the convex hull.\n\nhull(pp.points)\n\narray([[31.01, 81.21],\n       [ 8.23, 39.93],\n       [ 9.47, 31.02],\n       [22.52, 22.39],\n       [54.46,  8.48],\n       [79.26,  7.68],\n       [89.78, 42.53],\n       [98.73, 77.17],\n       [65.19, 92.08]])\n\n\nBy specifying “hull” argument True in PointPattern class method plot, we can easily plot convex hull of the point pattern.\n\npp.plot(title='Centers', hull=True ) #plot point pattern \"pp\" as well as its convex hull\nplt.plot(mc[0], mc[1], 'b^', label='Mean Center')\nplt.plot(wmc[0], wmc[1], 'gd', label='Weighted Mean Center')\nplt.plot(mm[0], mm[1], 'rv', label='Manhattan Median')\nplt.plot(em[0], em[1], 'm+', label='Euclidean Median')\nplt.legend(numpoints=1)\n\n<matplotlib.legend.Legend at 0x7f987fbcbe20>"
  },
  {
    "objectID": "slides/week-04/06-centrography.html#minimum-bounding-rectangle",
    "href": "slides/week-04/06-centrography.html#minimum-bounding-rectangle",
    "title": "Centrography for Point Patterns",
    "section": "Minimum Bounding Rectangle",
    "text": "Minimum Bounding Rectangle\nMinimum Bounding Rectangle (Box) is the same as the minimum bounding Rectangle of its convex hull. Thus, it is almost always bigger than convex hull.\nWe can call mbr function to calculate the leftmost, downmost, rightmost, and upmost value of the vertices of minimum bounding rectangle.\n\nmbr(pp.points)\n\n/tmp/ipykernel_831773/2243439823.py:1: FutureWarning: This function will be deprecated in the next release of pointpats.\n  mbr(pp.points)\n\n\n(8.23, 7.68, 98.73, 92.08)\n\n\nThus, four vertices of the minimum bounding rectangle is \\((8.23,7.68),(98.73,7.68),(98.73,92.08),(8.23,92.08)\\).\n\npp.plot(title='Centers', window=True ) #plot point pattern \"pp\" as well as its Minimum Bounding Rectangle\nplt.plot(mc[0], mc[1], 'b^', label='Mean Center')\nplt.plot(wmc[0], wmc[1], 'gd', label='Weighted Mean Center')\nplt.plot(mm[0], mm[1], 'rv', label='Manhattan Median')\nplt.plot(em[0], em[1], 'm+', label='Euclidean Median')\nplt.legend(numpoints=1)\n\n<matplotlib.legend.Legend at 0x7f987fae7b50>\n\n\n\n\n\n\npp.plot(title='Centers',  hull=True , window=True )#plot point pattern \"pp\", convex hull, and Minimum Bounding Rectangle\nplt.plot(mc[0], mc[1], 'b^', label='Mean Center')\nplt.plot(wmc[0], wmc[1], 'gd', label='Weighted Mean Center')\nplt.plot(mm[0], mm[1], 'rv', label='Manhattan Median')\nplt.plot(em[0], em[1], 'm+', label='Euclidean Median')\nplt.legend(numpoints=1)\n\n<matplotlib.legend.Legend at 0x7f987fb7b1f0>\n\n\n\n\n\nPlot Standard Distance Circle and Convex Hull.\n\ncircle1=plt.Circle((mc[0], mc[1]),stdd,color='r',alpha=0.2)\nax = pp.plot(get_ax=True, title='Standard Distance Circle', hull=True)\nax.add_artist(circle1)\nplt.plot(mc[0], mc[1], 'b^', label='Mean Center')\nax.set_aspect('equal')\nplt.legend(numpoints=1)\n\n<matplotlib.legend.Legend at 0x7f987f565a20>"
  },
  {
    "objectID": "slides/week-04/06-centrography.html#simulate-a-100-point-dataset-within-va-state-border-from-a-csr-complete-spatial-randomness-process.",
    "href": "slides/week-04/06-centrography.html#simulate-a-100-point-dataset-within-va-state-border-from-a-csr-complete-spatial-randomness-process.",
    "title": "Centrography for Point Patterns",
    "section": "Simulate a 100-point dataset within VA state border from a CSR (complete spatial randomness) process.",
    "text": "Simulate a 100-point dataset within VA state border from a CSR (complete spatial randomness) process.\n\npp = csr(as_window(state), 100, 1, asPP=True).realizations[0]\npp.plot(window=True)\n\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1923: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n\n\n\n\n\n\npp.plot(window=True, hull=True)\n\n\n\n\n\nmc = mean_center(pp.points)\nmm = manhattan_median(pp.points)\nem = euclidean_median(pp.points)\npp.plot(title='Centers',  hull=True , window=True )#plot point pattern \"pp\", convex hull, and Minimum Bounding Rectangle\nplt.plot(mc[0], mc[1], 'c^', label='Mean Center')\nplt.plot(mm[0], mm[1], 'rv', label='Manhattan Median')\nplt.plot(em[0], em[1], 'm+', label='Euclidean Median')\nplt.legend(numpoints=1)\n\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/pointpats/centrography.py:208: UserWarning: Manhattan Median is not unique for even point patterns.\n  warnings.warn(s)\n\n\n<matplotlib.legend.Legend at 0x7f987faa2d10>\n\n\n\n\n\nPlot Standard Distance Circle of the simulated point pattern.\n\nsx, sy, theta = ellipse(pp.points)\nsx, sy, theta\ntheta_degree = np.degrees(theta) #need degree of rotation to plot the ellipse\nfrom matplotlib.patches import Ellipse\nfrom pylab import figure, show,rand\nfig = figure()\n#ax = fig.add_subplot(111, aspect='equal')\ne = Ellipse(xy=mean_center(pp.points), width=sx*2, height=sy*2, angle=-theta_degree)\nax = pp.plot(get_ax=True, title='Standard Deviational Ellipse')\nax.add_artist(e)\ne.set_clip_box(ax.bbox)\ne.set_facecolor([0.8,0,0])\ne.set_edgecolor([1,0,0])\nax.set_xlim(300000,1000000)\nax.set_ylim(4050000,4350000)\n#ax.set_aspect('equal')\nplt.plot(mc[0], mc[1], 'c^', label='Mean Center')\nplt.legend(numpoints=1)\nshow()\n\n<Figure size 672x480 with 0 Axes>"
  },
  {
    "objectID": "slides/week-04/06-centrography.html#simulate-a-500-point-dataset-within-va-state-border-from-a-csr-complete-spatial-randomness-process.",
    "href": "slides/week-04/06-centrography.html#simulate-a-500-point-dataset-within-va-state-border-from-a-csr-complete-spatial-randomness-process.",
    "title": "Centrography for Point Patterns",
    "section": "Simulate a 500-point dataset within VA state border from a CSR (complete spatial randomness) process.",
    "text": "Simulate a 500-point dataset within VA state border from a CSR (complete spatial randomness) process.\n\npp = csr(as_window(state), 500, 1, asPP=True).realizations[0]\npp.plot(window=True)\n\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1492: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1208: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1923: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:103: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n\n\n\n\n\n\npp.plot(window=True, hull=True)\n\n\n\n\n\nmc = mean_center(pp.points)\nmm = manhattan_median(pp.points)\nem = euclidean_median(pp.points)\npp.plot(title='Centers',  hull=True , window=True )#plot point pattern \"pp\", convex hull, and Minimum Bounding Rectangle\nplt.plot(mc[0], mc[1], 'c^', label='Mean Center')\nplt.plot(mm[0], mm[1], 'rv', label='Manhattan Median')\nplt.plot(em[0], em[1], 'm+', label='Euclidean Median')\nplt.legend(numpoints=1)\n\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/pointpats/centrography.py:208: UserWarning: Manhattan Median is not unique for even point patterns.\n  warnings.warn(s)\n\n\n<matplotlib.legend.Legend at 0x7f987f80faf0>\n\n\n\n\n\n\nsx, sy, theta = ellipse(pp.points)\nsx, sy, theta\ntheta_degree = np.degrees(theta) #need degree of rotation to plot the ellipse\nfrom matplotlib.patches import Ellipse\nfrom pylab import figure, show,rand\nfig = figure()\n#ax = fig.add_subplot(111, aspect='equal')\ne = Ellipse(xy=mean_center(pp.points), width=sx*2, height=sy*2, angle=-theta_degree)\nax = pp.plot(get_ax=True, title='Standard Deviational Ellipse')\nax.add_artist(e)\ne.set_clip_box(ax.bbox)\ne.set_facecolor([0.8,0,0])\ne.set_edgecolor([1,0,0])\nax.set_xlim(300000,1000000)\nax.set_ylim(4050000,4350000)\n#ax.set_aspect('equal')\nplt.plot(mc[0], mc[1], 'c^', label='Mean Center')\nplt.legend(numpoints=1)\nshow()\n\n<Figure size 672x480 with 0 Axes>\n\n\n\n\n\nIf we calculate the Euclidean distances between every event point and Mean Center (Euclidean Median), and sum them up, we can see that Euclidean Median is the optimal point in iterms of minimizing the Euclidean distances to all the event points.\n\nfrom pointpats import dtot\nprint(dtot(mc, pp.points))\nprint(dtot(em, pp.points))\nprint(dtot(mc, pp.points) > dtot(em, pp.points))\n\n74417063.1370569\n74123909.89396742\nTrue"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html",
    "href": "slides/week-04/07-point-processes.html",
    "title": "Point Processes",
    "section": "",
    "text": "Thus far we have been looking at a collection of points as a point pattern.\nNow we want to take a different view of that pattern, one that sees the pattern as the outcome of a process.\nA point process is a statistical model that will generate point patterns with particular characteristics.\nFrom a scientific point of view we are interested in making inferences about the process that may have generated our point pattern."
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#first-order-properties",
    "href": "slides/week-04/07-point-processes.html#first-order-properties",
    "title": "Point Processes",
    "section": "First Order Properties",
    "text": "First Order Properties\n\nFirst Order Properties: Spatial Analysis\nMean value of the process in space\n\nVariation in mean value of the process in space\nGlobal, large scale spatial trend\n\nFirst Order Property of Point Patterns, Intensity: \\(\\lambda\\)\n\nIntensity: \\(\\lambda\\) = number of events expected per unit area\nEstimation of \\(\\lambda\\)\nSpatial variation of \\(\\lambda\\), \\(\\lambda(s)\\), \\(s\\) is a location\n\n\\[\\lambda(s) = \\lim_{ds\\rightarrow 0}\\left\\{ \\frac{E(Y(ds))}{ds} \\right\\}\\]"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#second-order-property",
    "href": "slides/week-04/07-point-processes.html#second-order-property",
    "title": "Point Processes",
    "section": "Second Order Property",
    "text": "Second Order Property\n\nSecond Order Properties: Spatial Analysis\nSpatial Correlation Structure\n\nDeviations in values from process mean\nLocal or small scale effects\n\nSecond Order Property of Point Patterns\n\nRelationship between number of events in pairs of areas\nSecond order intensity \\(\\gamma(s_i,s_j)\\)\n\n\\[\\gamma(s_i,s_j) = \\lim_{ds_i\\rightarrow 0,ds_j\\rightarrow 0}\\left\\{\n       \\frac{E(Y(ds_i)Y(ds_j))}{ds_ids_j} \\right\\}\\]"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#spatial-stationarity",
    "href": "slides/week-04/07-point-processes.html#spatial-stationarity",
    "title": "Point Processes",
    "section": "Spatial Stationarity",
    "text": "Spatial Stationarity\nFirst Order Stationarity \\[\\lambda(s) = \\lambda \\forall s \\in A\\] \\[E(Y(A)) = \\lambda \\times A\\]\nSecond Order Stationarity \\[\\gamma(s_i,s_j) = \\gamma(s_i - s_j) = \\gamma(h)\\]\n\n\\(h\\) is the vector difference between locations \\(s_i\\) and \\(s_j\\)\n\\(h\\) encompasses direction and distance (relative location)\nSecond order intensity only depends on \\(h\\) for second order stationarity"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#spatial-isotropy-and-stationarity",
    "href": "slides/week-04/07-point-processes.html#spatial-isotropy-and-stationarity",
    "title": "Point Processes",
    "section": "Spatial Isotropy and Stationarity",
    "text": "Spatial Isotropy and Stationarity\nIsotropic Process\n\nWhen a stationary process is invariant to rotation about the origin.\nRelationship between two events depend only on the distance separating their locations and not on their orientation to each other.\nDepends only on distance, not direction\n\nUsefulness\n\nTwo pairs of events from a stationary process separated by same distance and relative direction should have same “relatedness”\nTwo pairs of events from a stationary and isotropic process separated by the same distance (irrespective of direction) should have the same “relatedness”\nBoth allow for replication and the ability to carry out estimation of the underlying DGP."
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#invariance",
    "href": "slides/week-04/07-point-processes.html#invariance",
    "title": "Point Processes",
    "section": "Invariance",
    "text": "Invariance\n\n\n\n\n\n\n\nUnder Translation\n\n\n\n\n\n\n\nUnder Rotation\n\n\n\n\nFigure 1: Invariance"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#complete-spatial-randomness",
    "href": "slides/week-04/07-point-processes.html#complete-spatial-randomness",
    "title": "Point Processes",
    "section": "Complete Spatial Randomness",
    "text": "Complete Spatial Randomness\n\nCSR\n\nStandard of Reference\nUniform: each location has equal probability\nIndependent: location of points independent\nHomogeneous Planar Poisson Point Process\n\n\n\nPoisson Point Process\n\nIntensity\n\nnumber of points in region \\(A: N(A)\\)\nintensity: \\(\\lambda = N/|A|\\)\nimplies: \\(\\lambda |A|\\) points randomly scattered in a region with area \\(|A|\\)\ne.g., \\(10\\times 1\\) (points per \\(km^2\\))\n\n\n\nPoisson Distribution \\(N(A) \\sim Poi(\\lambda |A|)\\)"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#poisson-distribution",
    "href": "slides/week-04/07-point-processes.html#poisson-distribution",
    "title": "Point Processes",
    "section": "Poisson Distribution",
    "text": "Poisson Distribution\n\nSingle Parameter Distribution: \\(\\lambda |A|\\)\n\nGenerally, \\(\\lambda\\) is the number of events in some well defined interval\n\nTime: phone calls to operator in one hour\nTime: accidents at an intersection per week\nSpace: trees in a quadrat\n\nLet \\(x\\) be a Poisson random variable\n\n\\(E[x] = V[x]= \\lambda |A|\\)\n\n\n\n\nPoisson Distribution \\[P(x) =  \\frac{e^{-\\lambda |A|} (\\lambda |A|)^x}{x!}\\]"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#spatial-example",
    "href": "slides/week-04/07-point-processes.html#spatial-example",
    "title": "Point Processes",
    "section": "Spatial Example",
    "text": "Spatial Example\n\nCSR with \\(\\lambda = 5/km^2\\)\n\nRegion = Circle\n\narea = \\(|A| = \\pi r^2\\)\n\\(r=0.1\\ km\\) then area \\(\\approx 0.03 \\ km^2\\)\n\nProbability of Zero Points in Circle \\[\\begin{aligned}\n         P[N(A) = 0] &= &  e^{-\\lambda |A|} (\\lambda |A|)^x /x!\\\\\n                     &\\approx&e^{-5 \\times 0.03} (5 \\times 0.03)^0 /0!\\\\\n                     &\\approx&e^{-5 \\times 0.03} \\\\\n                     &\\approx&0.86\n       \\end{aligned}\\]"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#complete-spatial-randomness-csr",
    "href": "slides/week-04/07-point-processes.html#complete-spatial-randomness-csr",
    "title": "Point Processes",
    "section": "Complete Spatial Randomness (CSR)",
    "text": "Complete Spatial Randomness (CSR)\n\nHomogeneous spatial Poisson point process\n\nThe number of events occurring within a finite region \\(A\\) is a random variable following a Poisson distribution with mean \\(\\lambda|A|\\), with \\(|A|\\) denoting area of \\(A\\).\nGiven the total number of events \\(N\\) occurring within an area \\(A\\), the locations of the \\(N\\) events represent an independent random sample of \\(N\\) locations where each location is equally likely to be chosen as an event.\n\n\n\n\nCriterion 2 is the general concept of CSR (uniform (random)) distribution in \\(A\\).\nCriterion 1 pertains to the intensity \\(\\lambda\\)."
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#homogeneous-poisson-process",
    "href": "slides/week-04/07-point-processes.html#homogeneous-poisson-process",
    "title": "Point Processes",
    "section": "Homogeneous Poisson Process",
    "text": "Homogeneous Poisson Process\n\nImplications\n\nThe number of events in nonoverlapping regions in \\(A\\) are statistically independent.\nFor any region \\(R \\subset A\\): \\[\\lim_{|R| \\rightarrow 0} \\frac{Pr[exactly\\ one\\ event\\ in\\ R]}{|R|}\n      = \\lambda > 0\\]\n\\[\\lim_{|R| \\rightarrow 0} \\frac{Pr[more\\ than\\ one\\ event\\ in\\\n       R]}{|R|} = 0\\]\n\n\n:::"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#homogeneous-poisson-process-1",
    "href": "slides/week-04/07-point-processes.html#homogeneous-poisson-process-1",
    "title": "Point Processes",
    "section": "Homogeneous Poisson process",
    "text": "Homogeneous Poisson process\n\nImplications\n\n\\(\\lambda\\) is the intensity of the spatial point pattern.\nFor a Poisson random variable, \\(Y\\): \\[E[Y] = \\lambda = V[Y]\\]\nProvides the motivation for some quadrat tests of CSR hypothesis.\n\nIf \\(Y_R\\) is the count in quadrat \\(R\\)\nIf \\(\\widehat{E[Y]}< \\widehat{V[Y]}\\): overdispersion = spatial clustering\nIf \\(\\widehat{E[Y]}> \\widehat{V[Y]}\\): underdispersion = spatial uniformity"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#poisson-distribution-lambda20",
    "href": "slides/week-04/07-point-processes.html#poisson-distribution-lambda20",
    "title": "Point Processes",
    "section": "Poisson Distribution \\(\\lambda=20\\)",
    "text": "Poisson Distribution \\(\\lambda=20\\)\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nnp.random.seed(12345)\nxy = np.random.rand(20,2)\ndf = pd.DataFrame(data=xy, columns=['x','y'])\nsns.scatterplot(x='x', y='y', data=df);\ndf.shape\n\n(20, 2)\n\n\n\n\n\nThe example we just did is known as \\(n-conditioning\\) where we will always get \\(n\\) points for the CSR process.\nA slightly different approach to generating a random point process is to use \\(\\lambda-conditioning\\)\n\nfrom scipy.stats import poisson\nlam=20\nn = poisson.rvs(lam, 1)\nxy = np.random.rand(n,2)\ndf = pd.DataFrame(data=xy, columns=['x','y'])\nsns.scatterplot(x='x', y='y', data=df);\ndf.shape\n\n(26, 2)\n\n\n\n\n\nThe difference is the number of points in the pattern will always be \\(n\\) with \\(n-conditioning\\) but may not be \\(n\\) with \\(\\lambda-conditioning\\). The latter allows the intensity to be drawn from a Poisson distribution, then that becomes the parameter for the draw of the point pattern."
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#limitations-of-csr",
    "href": "slides/week-04/07-point-processes.html#limitations-of-csr",
    "title": "Point Processes",
    "section": "Limitations of CSR",
    "text": "Limitations of CSR\n\nStationary Poisson Process\n\nhomogeneous\ntranslation invaratiant\n\n\n\nRare in practice - very few actual processes are CSR\n\n\nStrawman\n\npurely a benchmark\nnull hypothesis"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#inhomogeneous-poisson-process-ipp",
    "href": "slides/week-04/07-point-processes.html#inhomogeneous-poisson-process-ipp",
    "title": "Point Processes",
    "section": "Inhomogeneous Poisson Process (IPP)",
    "text": "Inhomogeneous Poisson Process (IPP)\n\nCriteria\n\nThe number of events occurring within a finite region \\(A\\) is a random variable following a Poisson Distribution with mean \\(\\int_{A}\\lambda(s) ds\\).\nGiven the total number of events \\(N\\) occurring within \\(A\\), the \\(N\\) events represent an independent sample of \\(N\\) locations, with the probability of sampling a particular point \\(s\\) proportional to \\(\\lambda(s)\\).\n\n\n\nSpatially Variable Intensity \\(\\lambda(s)\\)\n\nUseful for constant risk hypothesis\nUnderlying population at risk is spatially clustered\nWant to control for that since with individual constant risk apparent clusters would be generated.\nCompare pattern against constant risk, not CSR."
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#inhomogeneous-poisson-process",
    "href": "slides/week-04/07-point-processes.html#inhomogeneous-poisson-process",
    "title": "Point Processes",
    "section": "Inhomogeneous Poisson Process",
    "text": "Inhomogeneous Poisson Process\n\nImplications\n\nApparent clusters can occur solely due to heterogeneities in the intensity function \\(\\lambda(s)\\).\nIndividual event locations still remain independent of one another.\nProcess is not stationary due to intensity heterogeneity\n\n\n\nHPP vs. IPP HPP is a special case of IPP with a constant intensity"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#csr-vs.-constant-risk-hypotheses",
    "href": "slides/week-04/07-point-processes.html#csr-vs.-constant-risk-hypotheses",
    "title": "Point Processes",
    "section": "CSR vs. Constant Risk Hypotheses",
    "text": "CSR vs. Constant Risk Hypotheses\n\nCSR\n\nIntensity is spatially constant\nPopulation at risk assumed spatially uniform\nUseful null hypothesis if these conditions are met\n\n\n\nConstant Risk Hypothesis\n\nPopulation density variable\nIndividual risk constant\nExpected number of events should vary with population density\nClusters due to deviation from CSR\nClusters due to deviation from CSR and Constant Risk"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#contagion-process-of-size-20-with-10-parents-and-2-children",
    "href": "slides/week-04/07-point-processes.html#contagion-process-of-size-20-with-10-parents-and-2-children",
    "title": "Point Processes",
    "section": "Contagion process of size 20 with 10 parents and 2 children",
    "text": "Contagion process of size 20 with 10 parents and 2 children\n\nimport pointpats as pp\nnp.random.seed(12345)\nw = pp.Window([(0,0), (0,1), (1,1), (1,0), (0,0)])\ndraw = pp.PoissonClusterPointProcess(w, 20, 10, 0.05, 1, asPP=True, conditioning=False)\ndraw.realizations[0].plot(window=True, title='Contagion Point Process (10 parents)')\n\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1492: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1208: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1923: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:103: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#contagion-process-of-size-20-with-2-parents-and-10-children",
    "href": "slides/week-04/07-point-processes.html#contagion-process-of-size-20-with-2-parents-and-10-children",
    "title": "Point Processes",
    "section": "Contagion process of size 20 with 2 parents and 10 children",
    "text": "Contagion process of size 20 with 2 parents and 10 children\n\nimport pointpats as pp\nnp.random.seed(12345)\nw = pp.Window([(0,0), (0,1), (1,1), (1,0), (0,0)])\ndraw = pp.PoissonClusterPointProcess(w, 20, 2, 0.05, 1, asPP=True, conditioning=False)\ndraw.realizations[0].plot(window=True, title='Contagion Point Process (2 parents)')\n\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1492: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1208: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1923: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:103: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#inhomogenous-poisson-process",
    "href": "slides/week-04/07-point-processes.html#inhomogenous-poisson-process",
    "title": "Point Processes",
    "section": "Inhomogenous Poisson Process",
    "text": "Inhomogenous Poisson Process\n\nIntensity varies with a covariate\n\ntrend surface\n\\(\\lambda(s) = exp(\\alpha + \\beta s)\\)\n\n\n\nIntensity varies with distance to a focus\n\n\\(\\lambda(s) = \\lambda 0(s). f( || s-s_0||, \\theta)\\)"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#simulating-an-inhomogeneous-poisson-point-process",
    "href": "slides/week-04/07-point-processes.html#simulating-an-inhomogeneous-poisson-point-process",
    "title": "Point Processes",
    "section": "Simulating An Inhomogeneous Poisson Point Process",
    "text": "Simulating An Inhomogeneous Poisson Point Process\nIntensity function:\n\\(\\lambda(s) = 100 e^{-(x^2 + y^2) / \\sigma}\\)\n\\(\\sigma\\) is a scale parameter here, equal to 0.5\n\n\nCode\nimport numpy as np;  # NumPy package for arrays, random number generation, etc\nimport matplotlib.pyplot as plt  # For plotting\nfrom scipy.optimize import minimize  # For optimizing\nfrom scipy import integrate  # For integrating\n\nplt.close('all');  # close all figures\n\n# Simulation window parameters\nxMin = 0;\nxMax = 1;\nyMin = 0;\nyMax = 1;\nxDelta = xMax - xMin;\nyDelta = yMax - yMin;  # rectangle dimensions\nareaTotal = xDelta * yDelta;\n\nnumbSim = 10 ** 3;  # number of simulations\ns = 0.5;  # scale parameter\n# Point process parameters\ndef fun_lambda(x, y):\n    return 100 * np.exp(-(x ** 2 + y ** 2) / s ** 2);  # intensity function\n#fun_lambda = lambda x,y: 100 * np.exp(-(x ** 2 + y ** 2) / s ** 2);\n\n###START -- find maximum lambda -- START ###\n# For an intensity function lambda, given by function fun_lambda,\n# finds the maximum of lambda in a rectangular region given by\n# [xMin,xMax,yMin,yMax].\ndef fun_Neg(x):\n    return -fun_lambda(x[0], x[1]);  # negative of lambda\n#fun_Neg = lambda x: -fun_lambda(x[0], x[1]);  # negative of lambda\n\nxy0 = [(xMin + xMax) / 2, (yMin + yMax) / 2];  # initial value(ie centre)\n# Find largest lambda value\nresultsOpt = minimize(fun_Neg, xy0, bounds=((xMin, xMax), (yMin, yMax)));\nlambdaNegMin = resultsOpt.fun;  # retrieve minimum value found by minimize\nlambdaMax = -lambdaNegMin;\n\n\n###END -- find maximum lambda -- END ###\n\n# define thinning probability function\ndef fun_p(x, y):\n    return fun_lambda(x, y) / lambdaMax;\n#fun_p = lambda x, y: fun_lambda(x, y) / lambdaMax;\n\n# for collecting statistics -- set numbSim=1 for one simulation\nnumbPointsRetained = np.zeros(numbSim);  # vector to record number of points\nfor ii in range(numbSim):\n    # Simulate a Poisson point process\n    numbPoints = np.random.poisson(areaTotal * lambdaMax);  # Poisson number of points\n    xx = np.random.uniform(0, xDelta, ((numbPoints, 1))) + xMin;  # x coordinates of Poisson points\n    yy = np.random.uniform(0, yDelta, ((numbPoints, 1))) + yMin;  # y coordinates of Poisson points\n\n    # calculate spatially-dependent thinning probabilities\n    p = fun_p(xx, yy);\n\n    # Generate Bernoulli variables (ie coin flips) for thinning\n    booleRetained = np.random.uniform(0, 1, ((numbPoints, 1))) < p;  # points to be retained\n\n    # x/y locations of retained points\n    xxRetained = xx[booleRetained];\n    yyRetained = yy[booleRetained];\n    numbPointsRetained[ii] = xxRetained.size;\n\n# Plotting\nplt.scatter(xxRetained, yyRetained, edgecolor='b', facecolor='none', alpha=0.5);\nplt.xlabel('x');\nplt.ylabel('y');\nplt.xlim([xMin, xMax]);\nplt.ylim([xMin, xMax]);\n\n\n\n\n\nsource\nThat pattern comes from a spatially-explicit thinning of a CSR pattern:\n\n\nCode\n# Plotting\nplt.scatter(xx, yy, edgecolor='b', facecolor='none', alpha=0.5);\nplt.xlabel('x');\nplt.ylabel('y');"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#regular-processes",
    "href": "slides/week-04/07-point-processes.html#regular-processes",
    "title": "Point Processes",
    "section": "Regular Processes",
    "text": "Regular Processes\n\nLess grouped than CSR\n\nfewer high densities\ndispersed\nrepulsion, competition\n\n\n\nUnderdispersion\n\nvariance < mean\nless variation in densities than CSR"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#inhibition-process",
    "href": "slides/week-04/07-point-processes.html#inhibition-process",
    "title": "Point Processes",
    "section": "Inhibition Process",
    "text": "Inhibition Process\n\nMinimum Permissible Distance\n\nno two points closer than \\(\\delta\\)\npacking intensity \\(\\tau = \\lambda \\pi \\delta^2 / 4\\)\n\n\n\nMatern Process\n\nthinned Poisson process using \\(\\delta\\)\nsequential inhibition process, generate points conditional on previous points and distance (denser than the thinned approach)"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#matern-thinning",
    "href": "slides/week-04/07-point-processes.html#matern-thinning",
    "title": "Point Processes",
    "section": "Matern (Thinning)",
    "text": "Matern (Thinning)\n\nnp.random.seed(12345)\ndelta = 0.1\nn = 20\nxy = np.random.random((n,2))\nxy\nfrom scipy.spatial import distance_matrix\n\nd = distance_matrix(xy, xy) # 20 x 20 distance matrix\nd[0] # first row\n\narray([0.        , 0.75403388, 0.4570564 , 0.33860475, 0.38256491,\n       0.67009276, 0.94484483, 0.716711  , 0.56856568, 0.40881349,\n       0.49326812, 0.46210886, 0.64101492, 0.36620498, 0.20105384,\n       1.02432357, 0.29284635, 0.4855703 , 0.42540863, 0.41333518])\n\n\nDetermine which observations to thin\n\nijs = np.where(d<delta)\ni,j = ijs\npairs = list(zip(i[i!=j], j[i!=j]))\nprint(\"The pairs within delta of one another:\")\nprint(pairs)\ndrop = []\n\nfor left, right in pairs:\n    if left in drop or right in drop:\n        continue\n    else:\n        drop.append(left)\n        \nprint(\"Observations to drop:\")\nprint(drop)\n\nThe pairs within delta of one another:\n[(3, 9), (3, 13), (9, 3), (9, 13), (9, 19), (13, 3), (13, 9), (19, 9)]\nObservations to drop:\n[3, 9]\n\n\n\nimport pandas as pd\ndf = pd.DataFrame(data=xy, columns=['x', 'y'])\ndf['thin'] = False\ndf.iloc[drop, df.columns.get_loc('thin')] = True\ndf.head()\n\n\n\n\n\n  \n    \n      \n      x\n      y\n      thin\n    \n  \n  \n    \n      0\n      0.929616\n      0.316376\n      False\n    \n    \n      1\n      0.183919\n      0.204560\n      False\n    \n    \n      2\n      0.567725\n      0.595545\n      False\n    \n    \n      3\n      0.964515\n      0.653177\n      True\n    \n    \n      4\n      0.748907\n      0.653570\n      False\n    \n  \n\n\n\n\n\nimport seaborn as sns\nsns.scatterplot(x='x', y='y', hue='thin', data=df);"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#matern-sequential",
    "href": "slides/week-04/07-point-processes.html#matern-sequential",
    "title": "Point Processes",
    "section": "Matern (Sequential)",
    "text": "Matern (Sequential)\n\ndelta = 0.1\nN = 20\nn = 1\nxy = np.zeros((N,2))\nxy[0,:] = np.random.rand(1,2)\nwhile n < N:\n    candidate = np.random.rand(1,2)\n    d = distance_matrix(xy[:n,:], candidate)\n    if d.min() > delta:\n        xy[n,:] = candidate\n        n += 1\n\ndf = pd.DataFrame(data=xy, columns=['x', 'y'])\nsns.scatterplot(x='x', y='y', data=df);"
  },
  {
    "objectID": "slides/week-04/07-point-processes.html#csr-n20",
    "href": "slides/week-04/07-point-processes.html#csr-n20",
    "title": "Point Processes",
    "section": "CSR n=20",
    "text": "CSR n=20\n\ndelta = 0.1\nxy = np.random.rand(20,2)\ndf = pd.DataFrame(data=xy, columns=['x', 'y'])\nsns.scatterplot(x='x', y='y', data=df);"
  },
  {
    "objectID": "syllabus.html#class-meetings",
    "href": "syllabus.html#class-meetings",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Class meetings",
    "text": "Class meetings\n\n\n\nMeeting\nLocation\nTime\n\n\n\n\nLecture\nGMCS 307\nTue & Thu 2:00 - 3:15pm"
  },
  {
    "objectID": "syllabus.html#teaching-team",
    "href": "syllabus.html#teaching-team",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Teaching team",
    "text": "Teaching team\n\n\n\nName\nOffice hours\nLocation\n\n\n\n\nSergio Rey\nThu 3:30 - 4:30pm (by appointment)\nPSFA 361G\n\n\nDylan Skrah\nTue 3:20-4:20pm\nPSFA 361F"
  },
  {
    "objectID": "syllabus.html#introduction",
    "href": "syllabus.html#introduction",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Introduction",
    "text": "Introduction\nWelcome to 385: Spatial Data Analysis!\nThe purpose of this course is to introduce you to methods of spatial data analysis. The focus is on both the conceptual and applied aspects of spatial statistical methods. We will place particular emphasis on the computational aspects of Exploratory Spatial Data Analysis (ESDA) methods for three diﬀerent types of spatial data: point processes, lattice, and geostatistical. We will also cover an introduction to regression analysis on spatially referenced data. Throughout the course you will gain valuable hands-on experience with several specialized software packages for spatial data analysis. The overriding goal of the course is for you to acquire familiarity with the fundamental methodological and operational issues in the statistical analysis of geographic information and the ability to extend these methods in your own research.\nThe course takes an explicitly computational thinking approach to its pedagogy. Students are introduced to computational concepts and tools that are increasingly important to research that engages with geospatial data. By adopting these tools, students acquire a deeper engagement with, and mastery of, the substantive concepts.\nIn the scope of a 15-week semester course we can only introduce a handful of the key concepts and methods relevant to the field of spatial data analysis. As such, the course is not intended as an exhaustive treatment. Instead, the goal is that students will acquire an understanding of the more common and useful methods and practices, and use the course as an entry point for further engagement with the field."
  },
  {
    "objectID": "syllabus.html#prerequisites",
    "href": "syllabus.html#prerequisites",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nGEOG 101 or GEOG 102\nSTAT 250 or comparable course in statistics.\n\nAll students are required to complete the prerequisite assessment quiz before Monday 1/24 11:59pm."
  },
  {
    "objectID": "syllabus.html#computational-learning",
    "href": "syllabus.html#computational-learning",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Computational Learning",
    "text": "Computational Learning\nWe will using open source geospatial software throughout the course together with Jupyter Notebooks, and Python as our scripting language.\nAll software for the course will be made available through JupyterHub a web-based framework. Students wishing to install these materials on their own machines will be given instructions to do so, but this is not required."
  },
  {
    "objectID": "syllabus.html#readings",
    "href": "syllabus.html#readings",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Readings",
    "text": "Readings\nAll required readings are available through the links listed below. Assigned readings should be completed before the date listed in the schedule (see below). Readings are a critical part of the discussions we will hold in class, and therefore coming into class prepared means having completed the readings and thought about the content. It will be difficult to do well in this course without having completed the readings.\n\n\n\n\n\n\n\nAbbrevation\nSource\n\n\n\n\nGDS\nRey, S.J., D. Arribas-Bel, L.J. Wolf (2023) Geographic Data Science with Python. CRC Press.\n\n\nGSA\nde Smith, M., M.F. Goodchild, P.A. Longly (2021) Geospatial Analysis. Winchelsea Press.\n\n\nSAH\nde Smith, M. (2021) Statistical Analysis Handbook. Drumlin Security Ltd."
  },
  {
    "objectID": "syllabus.html#schedule-planned",
    "href": "syllabus.html#schedule-planned",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Schedule (Planned)",
    "text": "Schedule (Planned)\n\n\n\nWeek\nDates\nTopic\nReading\nActivities\n\n\n\n\n1\nJan-19\nIntroduction\n\n\n\n\n2\nJan-24\nSpatial Analysis\nGDS 1\nQuiz 1\n\n\n\nJan-26\nSpatial Analysis Software\nGDS 2\nExercise 1 Out\n\n\n3\nJan-31\nSpatial Data\nGDS 3\nQuiz 2\n\n\n\nFeb-02\nPoint Pattern Basics\nGDS 8.1\n\n\n\n4\nFeb-07\nCentrography\nGDS 8.2\nQuiz 3\n\n\n\nFeb-09\nPoint Processes\n\n\n\n\n5\nFeb-14\nHands on Exercise 1\n\nQuiz 4\n\n\n\nFeb-16\nNearest Neighbor Methods\nGDS 8.3\nExercise 2 Out\n\n\n\n\n\n\nExericse 1 Due\n\n\n6\nFeb-21\nArea Data\nGDS II\nQuiz 5\n\n\n\nFeb-23\nVisualization of Area Data\nGDS 5\n\n\n\n7\nFeb-28\nSpatial Autocorrelation Concepts\nGDS 6.1\nQuiz 6\n\n\n\nMar-02\nSpatial Weights\nGDS 4\nExercise 2 Due\n\n\n8\nMar-07\nJoin Count Tests\nGDS 5.1\nQuiz 7\n\n\n\nMar-09\nGlobal Autocorrelation Tests\nGDS 5.2\n\n\n\n9\nMar-14\nLocal Autocorrelation\nGDS 6\nQuiz 8\n\n\n\nMar-16\nGeostatistical Data\nGSA gs\nExercise 3 Out\n\n\n10\nMar-21\nSpatial Interpolation\nGSA int\nQuiz 9\n\n\n\nMar-23\nKriging\nGSA krg\n\n\n\n\nMar-28\nSpring Break\n\n\n\n\n\nMar-30\nSpring Break\n\n\n\n\n11\nApr-04\nIntroduction to Multivariate Analysis\nSAH mv\nQuiz 10\n\n\n\nApr-06\nCorrelation and Spatial Correlation\nSAH cor\nExercise 3 Due\n\n\n12\nApr-11\nIntroduction to Regression\nGSA reg\nExercise 4 Out\n\n\n\nApr-13\nInference in Regression\nSAH inf\n\n\n\n13\nApr-18\nRegression with Spatial Data\nGDS 11\n\n\n\n\nApr-20\nDiagnostics for Spatial Effects\n\n\n\n\n14\nApr-25\nSpatial Dynamics\nGDS 9\nExercise 4 Due\n\n\n\nApr-27\nNext Steps With Spatial Data Analysis\n\n\n\n\n15\nMay-02\nPresentations\n\n\n\n\n\nMay-04\nPresentations\n\n\n\n\n\nMay-10\nFinal Examination (13:00-15:00)"
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Grading",
    "text": "Grading\nGEOG385 uses specification grading in evaluating student work and in determining your final course grade. Your course grade will be based on the quality and quantity of the work that you submit that is evaluated to be of an acceptable level of quality. The acceptable level of quality demonstrates competency in the concepts and methods covered in the course.\nThere is a two-step process for determination of your final course grade at the end of the quarter:\n\nUsing your quizzes, exercises, and projects, your base grade is determined.\nUsing your final exam results, determine if your base grade includes a \"plus\", \"minus\", or level drop to form the course grade.\n\nFor Step 1, the base grade is determined using the following specification:\n\n\n\nLevel\nHurdles\n\n\n\n\nA\nPass at least 8 of 10 quizzes, earn \"Demonstrates Competency\" on 4 of 4 exercises,\n\n\n\nand submit a project that earns \"Demonstrates Competency\"\n\n\nB\nPass at least 7 of 10 quizzes, earn \"Demonstrates Competency\" on 3 of 4 exercises\n\n\nC\nPass at least 6 of 10 quizzes, earn \"Demonstrates Competency\" on 2 of 4 exercises\n\n\nD\nPass at least 5 of 10 quizzes, earn \"Demonstrates Competency\" on 1 of 4 exercises\n\n\nF\nFail to clear D-level hurdles\n\n\n\nFor Step 2, your final course grade is determined as follows:\n\nIf you earn at least 85% on the final exam, you will obtain a + for your grade. So an A base grade becomes a final A+ course grade, a B becomes a B+, and so on.\nIf you score between 70-85% on the final exam, your base grade becomes your course grade.\nIf you score between 50% and 69% on the final exam, you will obtain a - for your grade. So an A becomes and A-, a B becomes a B-, and so on.\nIf you score less than 50% on the final exam, your course grade will drop one level: An A base grade becomes a final B course grade."
  },
  {
    "objectID": "syllabus.html#quizzes",
    "href": "syllabus.html#quizzes",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Quizzes",
    "text": "Quizzes\nQuizzes are graded on a pass/fail basis. Starting in week two, there will be a quiz due before each Tuesday session that pertains to the background reading that is required before our work in class."
  },
  {
    "objectID": "syllabus.html#exercises",
    "href": "syllabus.html#exercises",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Exercises",
    "text": "Exercises\nFour exercises will be introduced in class and are due in two weeks.\nEach exercise is graded using a CRN rubric that classifies work with marks of C (\"Demonstrates Competence\"), R (\"Needs Revision\"), or N (\"Not assessable\"):\nOf each exercise the following questions will be asked: Does the work demonstrate that the student understands the concepts? Does the work demonstrate competence and meet the expectations outlined in the exercise?\nIf the answer is \"yes\" to both of the questions, a student passes the hurdle for that exercise.\nIf the initial submission does not clear the hurdle, then a second question is asked: Is there evidence of partial understanding of the concepts? If the answer to this question is \"Yes\" the student can exchange one token to attempt a revision of their work. If the answer is \"No\", the student does not clear the hurdle for this exercise and will not have the opportunity to revise their work."
  },
  {
    "objectID": "syllabus.html#project",
    "href": "syllabus.html#project",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Project",
    "text": "Project\nThe project is a required hurdle to earn a level A grade. In order to clear this hurdle, the project must obtain a \"Demonstrates Competence\" evaluation. There will be opportunities for feedback along the way, but the final submission will be evaluated. There will be no opportunity for revising this final submission.\nStudents need to commit to the project by specifying their team (maximum of 4 members on a team) by 3-09. Once the commitment is made, the team composition is final. Any student who does not submit a team definition by this date will not be able to pursue the project.\nDetails on the project rubric will be given out on 2-16."
  },
  {
    "objectID": "syllabus.html#final-exam",
    "href": "syllabus.html#final-exam",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Final Exam",
    "text": "Final Exam\nA closed book, closed note, timed final exam will be given on May 10 (13:00-15:00). The exam will be based on a blend of previous quiz questions and additional questions that pertain to material covered in class."
  },
  {
    "objectID": "syllabus.html#tokens",
    "href": "syllabus.html#tokens",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Tokens",
    "text": "Tokens\nEach student is provided with three tokens at the beginning of the semester.\nUsing Tokens\n\nOne token can be used for a one-day extension for an exercise.\nOne token can be used to revise an exercise that was submitted on-time but evaluated as \"Needing Revision\".\nTwo tokens can be used to request a make-up date for the final exam.\n\nEarning Tokens\n\nHanding in an exercise at least 24 hours before its due date.\nSubmitting all four exercises on time (or early).\nAttempting all 10 quizzes.\n\nRemaining Tokens\nEach token that remains unused after 4-27 will be counted as a passed quiz. Tokens cannot be exchanged with other students."
  },
  {
    "objectID": "syllabus.html#policies",
    "href": "syllabus.html#policies",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Policies",
    "text": "Policies\n\nAccomodations\nIf you are a student with a disability and are in need of accommodations for this class, please contact Student Ability Success Center at (619) 594-6473 as soon as possible. Please know accommodations are not retroactive, and I cannot provide accommodations based upon disability until I have received an accommodation letter from Student Ability Success Center.\n\n\nPrivacy and Intellectual Property\nStudent Privacy and Intellectual Property: The Family Educational Rights and Privacy Act (FERPA) mandates the protection of student information, including contact information, grades, and graded assignments. I will use Canvas to communicate with you, and I will not post grades or leave graded assignments in public places. Students will be notified at the time of an assignment if copies of student work will be retained beyond the end of the semester or used as examples for future students or the wider public. Students maintain intellectual property rights to work products they create as part of this course unless they are formally notified otherwise.\n\n\nAcademic Integrity\nThe SDSU student academic integrity policy lists violations in detail. These violations fall into eight broad areas that include but are not limited to: cheating, fabrication, plagiarism, facilitating academic misconduct, unauthorized collaboration, interference or sabotage, non-compliance with research regulations and retaliation. For more information about the SDSU student academic integrity policy, please see the following: https://sacd.sdsu.edu/student-rights/academic-dishonesty.\n\n\nCode of Conduct\nAs course instructor, I am dedicated to providing a harassment-free learning experience for all students, regardless of gender, sexual orientation, disability, physical appearance, body size, race, religion, or choice of operating system. All course participants are expected to show respect and courtesy to other students throughout the semester. As a learning community we do not tolerate harassment of participants in any form.\n\nAll communication should be appropriate for a professional audience including people of many different backgrounds. Sexual language and imagery are not appropriate in this course.\nBe kind to others. Do not insult or put down other students. Behave professionally. Remember that harassment and sexist, racist, or exclusionary jokes are not appropriate for this course.\nStudents violating these rules may be asked to leave the course, and their violations will be reported to the SDSU administration.\n\nThis code of conduct is an adaptation of the SciPy 2018 Code of Conduct."
  },
  {
    "objectID": "weeks/week-01.html",
    "href": "weeks/week-01.html",
    "title": "Week 01",
    "section": "",
    "text": "Lectures\n\n\n\n\n\n\nTopic\n\n\nDate\n\n\n\n\n\n\nCourse Introduction\n\n\nThu, Jan 19\n\n\n\n\n\n\nNo matching items\n\n\n\n\nAssignments\n\n\n\n\n\n\nAssignment\n\n\nTitle\n\n\nDue\n\n\n\n\n\n\nQuiz\n\n\nPrerequisite Quiz\n\n\nMon, Jan 23\n\n\n\n\n\n\nNo matching items\n\n\n\n\nReadings\n\n\n\n\n\n\nCourse Syllabus"
  },
  {
    "objectID": "weeks/week-02.html",
    "href": "weeks/week-02.html",
    "title": "Week 02",
    "section": "",
    "text": "Lectures\n\n\n\n\n\n\nTopic\n\n\nDate\n\n\n\n\n\n\nSpatial Analysis\n\n\nTue, Jan 24\n\n\n\n\nSpatial Data Analysis Software\n\n\nThu, Jan 26\n\n\n\n\n\n\nNo matching items\n\n\n\n\nAssignments\n\n\n\n\n\n\nAssignment\n\n\nTitle\n\n\nDue\n\n\n\n\n\n\nQuiz\n\n\nQuiz 1\n\n\nTue, Jan 24\n\n\n\n\nExercise\n\n\nExercise 01\n\n\nThu, Feb 16\n\n\n\n\n\n\nNo matching items\n\n\n\n\nReadings\n\nGeographic Data Science with Python: Chapter 1 - Geographic Thinking for Data Scientists\nGeographic Data Science with Python: Chapter 2 - Computational Tools for Geographic Data Science"
  },
  {
    "objectID": "weeks/week-03.html",
    "href": "weeks/week-03.html",
    "title": "Week 03",
    "section": "",
    "text": "Lectures\n\n\n\n\n\n\nTopic\n\n\nDate\n\n\n\n\n\n\nSpatial Data\n\n\nTue, Jan 31\n\n\n\n\nPoint Pattern Basics\n\n\nThu, Feb 02\n\n\n\n\n\n\nNo matching items\n\n\n\n\nAssignments\n\n\n\n\n\n\nAssignment\n\n\nTitle\n\n\nDue\n\n\n\n\n\n\nQuiz\n\n\nQuiz 2\n\n\nTue, Jan 31\n\n\n\n\n\n\nNo matching items\n\n\n\n\nReadings\n\nGeographic Data Science with Python: Chapter 3 - Spatial Data\nGeographic Data Science with Python: Chapter 8.1 - Point Pattern Analysis"
  },
  {
    "objectID": "weeks/week-04.html",
    "href": "weeks/week-04.html",
    "title": "Week 04",
    "section": "",
    "text": "Lectures\n\n\n\n\n\n\nTopic\n\n\nDate\n\n\n\n\n\n\nCentrography for Point Patterns\n\n\nTue, Feb 07\n\n\n\n\nPoint Processes\n\n\nThu, Feb 09\n\n\n\n\n\n\nNo matching items\n\n\n\n\nAssignments\n\n\n\n\n\n\nAssignment\n\n\nTitle\n\n\nDue\n\n\n\n\n\n\nQuiz\n\n\nQuiz 3\n\n\nTue, Feb 07\n\n\n\n\n\n\nNo matching items\n\n\n\n\nReadings\n\nGeographic Data Science with Python: 8.2 - Point Pattern Analysis"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Materials will be posted here as the semester progresses\n\n\n\n\n\n\nWeek\n\n\nDates\n\n\nTopic\n\n\n\n\n\n\nWeek 01\n\n\nJan 19\n\n\nWelcome to Spatial Data Analysis\n\n\n\n\nWeek 02\n\n\nJan 24 - 26\n\n\nSpatial Analysis\n\n\n\n\nWeek 03\n\n\nJan 31 - Feb 2\n\n\nSpatial Data and Point Pattern Analysis\n\n\n\n\nWeek 04\n\n\nFeb 7 - Feb 9\n\n\nPoint Pattern Analysis - Centrography and Point Processes\n\n\n\n\nWeek 05\n\n\nFeb 14 - Feb 16\n\n\nPoint Pattern Analysis - Nearest Neighbor Methods\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "schedule.html#assignments",
    "href": "schedule.html#assignments",
    "title": "Schedule",
    "section": "Assignments",
    "text": "Assignments\nYou can find details and assignment instructions in the relevant week on the schedule.\n\nExercises\nExercises will be due on Thursdays at 2:00pm. You will have two weeks to complete each homework assignment. Details will be provided on the weekly schedule.\n\n\nQuizzes\nOn-line quizzes are due on Tuesdays at 2:00pm. Details are available by week in the schedule.\n\n\nExam\nThere will be a final exam on May 19 (13:00-15:00)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Spatial Data Analysis",
    "section": "",
    "text": "Course overview from GEOG 385: Spatial Data Analysis at San Diego State University\nThe purpose of this course is to introduce you to methods of spatial data analysis. The focus is on both the conceptual and applied aspects of spatial statistical methods. We will place particular emphasis on the computational aspects of Exploratory Spatial Data Analysis (ESDA) methods for three diﬀerent types of spatial data: point processes, lattice, and geostatistical. We will also cover an introduction to regression analysis on spatially referenced data. Throughout the course you will gain valuable hands-on experience with several specialized software packages for spatial data analysis. The overriding goal of the course is for you to acquire familiarity with the fundamental methodological and operational issues in the statistical analysis of geographic information and the ability to extend these methods in your own research."
  },
  {
    "objectID": "index.html#class-meetings",
    "href": "index.html#class-meetings",
    "title": "Spatial Data Analysis",
    "section": "Class meetings",
    "text": "Class meetings\n\n\n\nMeeting\nLocation\nTime\n\n\n\n\nLecture\nGMCS 307\nTue & Thu 2:00 - 3:15pm"
  },
  {
    "objectID": "index.html#teaching-team",
    "href": "index.html#teaching-team",
    "title": "Spatial Data Analysis",
    "section": "Teaching team",
    "text": "Teaching team\n\n\n\nName\nOffice hours\nLocation\n\n\n\n\nSergio Rey\nThu 3:30 - 4:30pm\nPSFA 361G\n\n\nDylan Skrah\nTue 3:20-4:20pm\nPSFA 361F"
  },
  {
    "objectID": "slides/week-05/0216_nearest_neighbor.html",
    "href": "slides/week-05/0216_nearest_neighbor.html",
    "title": "Nearest Neighbor Methods",
    "section": "",
    "text": "Now that we have been introduced to the different statistical models than are used to represent point processes, we turn to the methods that are used to link observed point patterns back to the process that generated the pattern.\nMore specifically, the challenge that we face is as follows. Given an observed point pattern, we wish to make inferences about the process that generated the observed pattern.\nThe general approach that is used is to construct measures that characterise the observed point pattern, and then compare these against the proporties of the theoretical process models we explored previously.\nFor example, if we assume that the underlying process is CSR, we know what kinds of properties the empirical patterns from such a process should exhibit. The critical thing to keep in mind is that we never actually see the underlying process - we only see outcomes of the process (i.e., the pattern).\nThis raises a number of challenges that we will need to address later on, but for now we are going to build up an inituition of the general strategy for analyzing point patterns."
  },
  {
    "objectID": "slides/week-05/0216_nearest_neighbor.html#example-patterns",
    "href": "slides/week-05/0216_nearest_neighbor.html#example-patterns",
    "title": "Nearest Neighbor Methods",
    "section": "Example Patterns",
    "text": "Example Patterns\nTo begin we are going to create two different point patterns, one from a CSR process and one from a clustered process. We will use these two patterns to introduce the different statistical methods used to analyze the patterns. Here we are in the rare circumstance in which we actually know what process generated the pattern.\n\nCSR n=60\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nnp.random.seed(12345)\nn = 60\nxy = np.random.rand(60,2)\ndf = pd.DataFrame(data=xy, columns=['x', 'y'])\nsns.scatterplot(x='x', y='y', data=df);\n\n\n\n\n\nimport pointpats as pp\n\n\ncsr = pp.PointPattern(xy)\n\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1492: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1208: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n\n\n\ncsr.summary()\n\nPoint Pattern\n60 points\nBounding rectangle [(0.00838829794155349,0.024676210429265266), (0.9940145858999619,0.9613067360728214)]\nArea of window: 0.9231676681785911\nIntensity estimate for window: 64.99361066054225\n          x         y\n0  0.929616  0.316376\n1  0.183919  0.204560\n2  0.567725  0.595545\n3  0.964515  0.653177\n4  0.748907  0.653570\n\n\n\nw = pp.Window([(0,0), (0,1), (1,1), (1,0), (0,0)])\ndraw = pp.PoissonClusterPointProcess(w, n, 2, 0.05, 1, asPP=True, conditioning=False)\ndraw.realizations[0].plot(window=True, title='Contagion Point Process (2 parents)')\n\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1492: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1208: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1923: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:103: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n\n\n\n\n\n\nclustered = draw.realizations[0]\n\n\nclustered.summary()\n\nPoint Pattern\n60 points\nBounding rectangle [(0.47331760265312733,0.023178703349462502), (0.9696584457277277,0.6150208352748628)]\nArea of window: 1.0\nIntensity estimate for window: 60.0\n          x         y\n0  0.513060  0.541971\n1  0.473318  0.578385\n2  0.508373  0.536200\n3  0.881716  0.060328\n4  0.894221  0.059273"
  },
  {
    "objectID": "slides/week-05/0216_nearest_neighbor.html#quadrat-statistics",
    "href": "slides/week-05/0216_nearest_neighbor.html#quadrat-statistics",
    "title": "Nearest Neighbor Methods",
    "section": "Quadrat Statistics",
    "text": "Quadrat Statistics\n\nimport pointpats.quadrat_statistics as qs\n\n\ncsr_qr = qs.QStatistic(csr, shape='rectangle', nx=3, ny=3)\ncsr_qr.plot()\n\n\n\n\n\ncsr_qr.chi2\n\n10.8\n\n\n\ncsr_qr.chi2_pvalue\n\n0.21329101843394052\n\n\n\nclustered_qr = qs.QStatistic(clustered, shape='rectangle', nx=3, ny=3)\nclustered_qr.plot()\n\n\n\n\n\nclustered_qr.chi2\n\n209.99999999999994\n\n\n\nclustered_qr.chi2_pvalue\n\n4.976940117448032e-41"
  },
  {
    "objectID": "slides/week-05/0216_nearest_neighbor.html#nearest-neighbor-distances",
    "href": "slides/week-05/0216_nearest_neighbor.html#nearest-neighbor-distances",
    "title": "Nearest Neighbor Methods",
    "section": "Nearest Neighbor Distances",
    "text": "Nearest Neighbor Distances\n\nplt.scatter(csr.points.x, csr.points.y);\n\n\n\n\n\nimport networkx as nx\n\n\nG = nx.DiGraph()\nfor idx, point in enumerate(csr.points.values):\n    G.add_node(idx, pos=point)\n    \n\n\npos = nx.get_node_attributes(G, 'pos')\nnx.draw(G, pos, node_size=2)\n\n\n\n\n\nnidx, nnd = csr.knn(1) # here we have the indices of the nearest neighbors (nidx) and the distances (nnd)\n\n\nfor idx, neighbor in enumerate(nidx):\n    edge = (idx, neighbor[0])\n    G.add_edges_from([edge])\n    \n\n\npos = nx.get_node_attributes(G, 'pos')\nnx.draw(G, pos, node_size=2)\n\n\n\n\nHere we draw an arrow towards the nearest neighbor for a given observation.\nIn some cases, an observation is also the nearest neighbor to its nearest neighbor, or so-called “mutual nearest neighbors”. These pairs would appear at the the end of a segment with arrows on both ends.\nIf we look in the extreme northwest three points, we see one pair of mutual nearest neighbors, while the third point is not a mutual nearest neighbor.\nIt is also possible for a point to be a nearest neighbor to more than a single point, as is also seen in this case.\nThe nearest neighbor distances are the lengths of these segments.\n\nMean Nearest Neighbor Distance\nOur first distance based statistic was suggested by Clark and Evans (1954) as the average nearest neighbor distances:\n\\[\\bar{d}_{min} = \\frac{1}{n} \\sum_{i} d_{i, min} \\]\nwhere \\(d_{i, min}\\) is the nearest neighbor distance for observation \\(i\\), and \\(n\\) is the number of observations.\nUnder a CSR process, the expected value of this statistic is:\n\\[E[\\bar{d}_{min}] = \\frac{1}{2 \\sqrt{\\lambda}}\\]\nThe logic of the statistic is to compare the observed mean nearest neighbor distance to this expectation forming their ratio:\n\\[R = \\frac{\\bar{d}_{min}}{\\frac{1}{2 \\sqrt{\\lambda}}} = 2 \\bar{d}_{min} \\sqrt{\\lambda}\\]\nValues of \\(R<1\\) are indicative of a tendancy towards clustering since the observed nearest neighbor distances are smaller than expected under CSR.\nValues of \\(R>1\\) are indicative of a uniform or dispersed pattern.\n\nnnd.mean() # the mean nearest neighbor distance\n\n0.07360281110243255\n\n\n\ncsr.lambda_window # the intensity using the window for the point pattern\n\n64.99361066054225\n\n\n\ndmin = nnd.mean()\nlam = csr.lambda_window\nR = 2 * dmin * lam**(1/2)\nR\n\n1.1867513365512292\n\n\nLet’s compare this to the same statistic based on the mean nearest neighbor distance for the clustered pattern:\n\nnidx, nnd = clustered.knn(1) # here we have the indices of the nearest neighbors (nidx) and the distances (nnd)\n\n\ndmin = nnd.mean()\nlam = clustered.lambda_window\nR = 2 * dmin * lam**(1/2)\nR\n\n0.13087134840769868\n\n\nSo we see that the \\(R\\) value for the clustered pattern is much below 1, while the R value for the CSR pattern is slightly over 1.\nWhat we would like to know is if these values are significantly different from what we would expect if the underlying process that generated the patterns was CSR?\nOne approach is to use theoretical results on the distribution for the \\(R\\) statistic from Petrere (1985). The expected value of \\(R\\) is \\(E[R]=1\\). The variance of the \\(R\\) statistic is: \\[ \\sigma^2_R = \\frac{0.2732}{n}\\]\n\nimport scipy.stats\ndef R_test(pattern):\n    nidx, nnd = pattern.knn(1) # here we have the indices of the nearest neighbors (nidx) and the distances (nnd)\n    lam = pattern.lambda_window\n    R = 2 * nnd.mean() * lam**(1/2)\n    n = nnd.shape[0]\n    var = 0.2732 / n\n    se = var**(1/2)\n    stat = (R - 1 )/ se\n    p_value = scipy.stats.norm.sf(abs(stat)) * 2\n    return R, stat, p_value\n\n\nR_test(csr)\n\n(1.1867513365512292, 2.7675724348891184, 0.005647549379017388)\n\n\n\nR_test(clustered)\n\n(0.13087134840769868, -12.880103258909552, 5.825756575218341e-38)\n\n\n\n\nInference via simulation\n\nimport pointpats\nimport numpy\nsamples = pointpats.PoissonPointProcess(csr.window, n, 99, asPP=True)\n\nr_tests = np.array([R_test(samples.realizations[k]) for k in samples.realizations])\n\nr_tests\n\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:1923: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:103: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n\n\narray([[ 9.81105197e-01, -2.80012645e-01,  7.79467803e-01],\n       [ 9.28415089e-01, -1.06085681e+00,  2.88754981e-01],\n       [ 1.05435206e+00,  8.05473519e-01,  4.20546481e-01],\n       [ 1.11821360e+00,  1.75187335e+00,  7.97955886e-02],\n       [ 1.12387424e+00,  1.83576157e+00,  6.63929272e-02],\n       [ 1.16724422e+00,  2.47848561e+00,  1.31941433e-02],\n       [ 1.10700813e+00,  1.58581325e+00,  1.12781678e-01],\n       [ 1.09108797e+00,  1.34988348e+00,  1.77053361e-01],\n       [ 9.69002352e-01, -4.59371472e-01,  6.45967431e-01],\n       [ 1.03760497e+00,  5.57289124e-01,  5.77329905e-01],\n       [ 1.02704882e+00,  4.00851546e-01,  6.88529426e-01],\n       [ 1.10508460e+00,  1.55730742e+00,  1.19397514e-01],\n       [ 1.15793416e+00,  2.34051463e+00,  1.92571837e-02],\n       [ 1.04250723e+00,  6.29938355e-01,  5.28734918e-01],\n       [ 1.10758728e+00,  1.59439606e+00,  1.10847354e-01],\n       [ 1.07177650e+00,  1.06369612e+00,  2.87466383e-01],\n       [ 1.02551521e+00,  3.78124168e-01,  7.05338356e-01],\n       [ 9.46840660e-01, -7.87797970e-01,  4.30814888e-01],\n       [ 1.03757582e+00,  5.56857151e-01,  5.77625033e-01],\n       [ 9.90592969e-01, -1.39408044e-01,  8.89127716e-01],\n       [ 1.04856233e+00,  7.19672330e-01,  4.71726767e-01],\n       [ 1.10811705e+00,  1.60224699e+00,  1.09101003e-01],\n       [ 9.54688187e-01, -6.71501077e-01,  5.01901374e-01],\n       [ 1.10995667e+00,  1.62950930e+00,  1.03205247e-01],\n       [ 1.15162238e+00,  2.24697675e+00,  2.46415129e-02],\n       [ 9.31182120e-01, -1.01985062e+00,  3.07799310e-01],\n       [ 9.71814911e-01, -4.17690588e-01,  6.76173355e-01],\n       [ 1.14149435e+00,  2.09688392e+00,  3.60038522e-02],\n       [ 1.07165594e+00,  1.06190948e+00,  2.88276781e-01],\n       [ 1.14437709e+00,  2.13960485e+00,  3.23867145e-02],\n       [ 9.26536025e-01, -1.08870370e+00,  2.76284570e-01],\n       [ 1.00659687e+00,  9.77627322e-02,  9.22120701e-01],\n       [ 1.19240160e+00,  2.85130688e+00,  4.35399261e-03],\n       [ 1.02219381e+00,  3.28902433e-01,  7.42229435e-01],\n       [ 1.17405296e+00,  2.57938804e+00,  9.89755372e-03],\n       [ 1.15649472e+00,  2.31918276e+00,  2.03851289e-02],\n       [ 9.45617539e-01, -8.05924083e-01,  4.20286624e-01],\n       [ 1.05893614e+00,  8.73407565e-01,  3.82440969e-01],\n       [ 1.09368529e+00,  1.38837464e+00,  1.65022993e-01],\n       [ 1.07631454e+00,  1.13094776e+00,  2.58077078e-01],\n       [ 9.78530574e-01, -3.18167420e-01,  7.50357945e-01],\n       [ 1.07064731e+00,  1.04696203e+00,  2.95117090e-01],\n       [ 1.08860485e+00,  1.31308486e+00,  1.89154355e-01],\n       [ 1.19551229e+00,  2.89740597e+00,  3.76262510e-03],\n       [ 1.07442246e+00,  1.10290799e+00,  2.70067126e-01],\n       [ 1.09651586e+00,  1.43032247e+00,  1.52624489e-01],\n       [ 1.10573862e+00,  1.56699976e+00,  1.17114749e-01],\n       [ 9.18296882e-01, -1.21080418e+00,  2.25970464e-01],\n       [ 9.75959250e-01, -3.56273307e-01,  7.21635897e-01],\n       [ 1.12270070e+00,  1.81837021e+00,  6.90075678e-02],\n       [ 1.16124927e+00,  2.38964311e+00,  1.68647518e-02],\n       [ 1.14288622e+00,  2.11751071e+00,  3.42165274e-02],\n       [ 8.95782250e-01, -1.54446109e+00,  1.22476670e-01],\n       [ 1.05289923e+00,  7.83943286e-01,  4.33073389e-01],\n       [ 1.21757563e+00,  3.22437488e+00,  1.26248010e-03],\n       [ 1.03138599e+00,  4.65126525e-01,  6.41840852e-01],\n       [ 1.07305973e+00,  1.08271294e+00,  2.78935859e-01],\n       [ 1.11578890e+00,  1.71594046e+00,  8.61729410e-02],\n       [ 9.58111837e-01, -6.20764093e-01,  5.34754852e-01],\n       [ 9.37476396e-01, -9.26572231e-01,  3.54148678e-01],\n       [ 9.63173031e-01, -5.45759439e-01,  5.85231308e-01],\n       [ 1.03085430e+00,  4.57247129e-01,  6.47493427e-01],\n       [ 1.12588430e+00,  1.86554984e+00,  6.21043732e-02],\n       [ 1.04886527e+00,  7.24161732e-01,  4.68966450e-01],\n       [ 1.11417108e+00,  1.69196511e+00,  9.06526264e-02],\n       [ 9.09443001e-01, -1.34201478e+00,  1.79591204e-01],\n       [ 1.11892848e+00,  1.76246763e+00,  7.79903206e-02],\n       [ 1.14728332e+00,  2.18267389e+00,  2.90598342e-02],\n       [ 9.66649872e-01, -4.94234183e-01,  6.21140802e-01],\n       [ 1.01975820e+00,  2.92807770e-01,  7.69669089e-01],\n       [ 1.06807716e+00,  1.00887343e+00,  3.13035340e-01],\n       [ 8.87332323e-01, -1.66968527e+00,  9.49816494e-02],\n       [ 1.06116818e+00,  9.06485480e-01,  3.64678947e-01],\n       [ 9.73221131e-01, -3.96851022e-01,  6.91477323e-01],\n       [ 1.10831264e+00,  1.60514552e+00,  1.08461783e-01],\n       [ 1.15121609e+00,  2.24095569e+00,  2.50289451e-02],\n       [ 1.06442269e+00,  9.54715861e-01,  3.39721407e-01],\n       [ 1.09045697e+00,  1.34053244e+00,  1.80072304e-01],\n       [ 1.21321146e+00,  3.15969983e+00,  1.57931759e-03],\n       [ 1.03753327e+00,  5.56226553e-01,  5.78055989e-01],\n       [ 9.92381824e-01, -1.12898015e-01,  9.10111410e-01],\n       [ 9.89597771e-01, -1.54156441e-01,  8.77486386e-01],\n       [ 8.69471915e-01, -1.93436865e+00,  5.30678183e-02],\n       [ 1.07456759e+00,  1.10505883e+00,  2.69134096e-01],\n       [ 1.01501782e+00,  2.22557427e-01,  8.23879974e-01],\n       [ 1.06339883e+00,  9.39542766e-01,  3.47452146e-01],\n       [ 1.04251892e+00,  6.30111598e-01,  5.28621572e-01],\n       [ 1.01595310e+00,  2.36417893e-01,  8.13108413e-01],\n       [ 9.76030325e-01, -3.55220016e-01,  7.22424770e-01],\n       [ 1.02700974e+00,  4.00272457e-01,  6.88955852e-01],\n       [ 1.05167838e+00,  7.65850808e-01,  4.43765079e-01],\n       [ 1.03268084e+00,  4.84315702e-01,  6.28161834e-01],\n       [ 1.07237329e+00,  1.07254022e+00,  2.83477458e-01],\n       [ 1.17864464e+00,  2.64743472e+00,  8.11050176e-03],\n       [ 1.00495856e+00,  7.34836527e-02,  9.41421252e-01],\n       [ 9.57599581e-01, -6.28355512e-01,  5.29771074e-01],\n       [ 1.01309195e+00,  1.94016950e-01,  8.46162610e-01],\n       [ 1.06834012e+00,  1.01277043e+00,  3.11169828e-01],\n       [ 1.04123161e+00,  6.11034274e-01,  5.41176890e-01]])\n\n\n\nR_csr = R_test(csr)\n\n\nR_csr[0]\n\n1.1867513365512292\n\n\n\n(r_tests[:,0] >= R_csr[0]).sum()\n\n4\n\n\n\nR_clustered = R_test(clustered)\n\n\nimport pandas\n\nimport seaborn as sns\n\n\ndf = pandas.DataFrame(data=r_tests, columns=['R', 'z', 'p'])\n\nsns.displot(df, kind='kde', x=\"R\")\nplt.axvline(R_csr[0], 0, 0.1, color='g');\nplt.axvline(R_clustered[0], 0, 0.1, color='r');\n\n\n\n\n\ndf.describe()\n\n\n\n\n\n  \n    \n      \n      R\n      z\n      p\n    \n  \n  \n    \n      count\n      99.000000\n      99.000000\n      99.000000\n    \n    \n      mean\n      1.052286\n      0.774857\n      0.357230\n    \n    \n      std\n      0.078631\n      1.165280\n      0.282182\n    \n    \n      min\n      0.869472\n      -1.934369\n      0.001262\n    \n    \n      25%\n      0.991487\n      -0.126153\n      0.099093\n    \n    \n      50%\n      1.054352\n      0.805474\n      0.295117\n    \n    \n      75%\n      1.108215\n      1.603696\n      0.581644\n    \n    \n      max\n      1.217576\n      3.224375\n      0.941421\n    \n  \n\n\n\n\n\n\nsamples = pointpats.PoissonPointProcess(csr.window, n, 999, asPP=True)\n\nr_tests = np.array([R_test(samples.realizations[k]) for k in samples.realizations])\n\nr_tests\n\n/home/serge/miniconda3/envs/libpysal/lib/python3.10/site-packages/libpysal/cg/shapes.py:103: FutureWarning: Objects based on the `Geometry` class will deprecated and removed in a future version of libpysal.\n  warnings.warn(dep_msg, FutureWarning)\n\n\narray([[ 1.04108274,  0.60882811,  0.54263838],\n       [ 1.08726785,  1.2932711 ,  0.19591731],\n       [ 0.96240692, -0.5571128 ,  0.57745036],\n       ...,\n       [ 1.18467435,  2.73679237,  0.00620414],\n       [ 1.05998867,  0.88900566,  0.37400004],\n       [ 0.92024492, -1.18193507,  0.23723146]])\n\n\n\ndf = pandas.DataFrame(data=r_tests, columns=['R', 'z', 'p'])\n\nsns.displot(df, kind='kde', x=\"R\")\nplt.axvline(R_csr[0], 0, 0.1, color='g');\nplt.axvline(R_clustered[0], 0, 0.1, color='r');\n\n\n\n\n\ndf.describe()\n\n\n\n\n\n  \n    \n      \n      R\n      z\n      p\n    \n  \n  \n    \n      count\n      999.000000\n      999.000000\n      999.000000\n    \n    \n      mean\n      1.057947\n      0.858756\n      0.357294\n    \n    \n      std\n      0.077832\n      1.153438\n      0.296165\n    \n    \n      min\n      0.805327\n      -2.884969\n      0.000001\n    \n    \n      25%\n      1.004814\n      0.071334\n      0.092286\n    \n    \n      50%\n      1.061867\n      0.916842\n      0.283196\n    \n    \n      75%\n      1.111235\n      1.648461\n      0.577714\n    \n    \n      max\n      1.328334\n      4.865765\n      0.998563"
  },
  {
    "objectID": "weeks/week-05.html",
    "href": "weeks/week-05.html",
    "title": "Week 05",
    "section": "",
    "text": "Lectures\n\n\n\n\n\n\nTopic\n\n\nDate\n\n\n\n\n\n\nExercise 1\n\n\nTue, Feb 14\n\n\n\n\nNearest Neighbor Methods\n\n\nThu, Feb 16\n\n\n\n\n\n\nNo matching items\n\n\n\n\nAssignments\n\n\n\n\n\n\nAssignment\n\n\nTitle\n\n\nDue\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\nReadings\n\nGeographic Data Science with Python: 8.3 - Point Pattern Analysis"
  },
  {
    "objectID": "slides/week-05/0214_exercise1.html",
    "href": "slides/week-05/0214_exercise1.html",
    "title": "Exercise 1",
    "section": "",
    "text": "Complete all the tasks below in this notebook (you must show the code used to get your answers).\nSave and Export As - PDF\nUpload your pdf to the Canvas site\n\nDue February 16 2pm\n\n\nCreate a folder called exercise using the File Explorer in Jupyter Hub\nIn that folder, copy this file, and do all your work in that file/notebook\n\nimport geopandas \nimport pandas\nimport matplotlib.pyplot as plt\nimport numpy\nimport seaborn\nimport contextily\n\n\n\n\nCreate a GeoDataFrame called: sd_gdf that contains the data from the file /data/shared/tims/sdcounty_2020_fatal.geojson\n\n\n\n\n\n\n\n\n\n\n\n\nProvide an explanation of what sd_gdf.crs reports. What is this attribute used for? What does the code mean\n\n\n\nCreate an east spatial variable using the median longitude value for the geodataframe.\nUse the plot method to create a categorical map of accidents by east-west.\nAre the number of fatalities different between the accidents in the west and east?\n\n\n\nUsing groupby explore whether Alcohol is more prevalant in the weekend fatal accidents than the weekday fatal accidents."
  }
]